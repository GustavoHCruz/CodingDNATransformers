{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c37f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1e763",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd91030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llms.nucl_classifier.bert import NuclBERT\n",
    "from schemas.train_params import TrainParams\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a404f87",
   "metadata": {},
   "source": [
    "## Params and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d58f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "\n",
    "csv_path = \"nucl-500.csv\"\n",
    "pretrained_model_name = \"NuclBERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b78c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = f\"./storage/data/processed/{csv_path}\"\n",
    "output_path = f\"./storage/models/tuned/{pretrained_model_name}\"\n",
    "checkpoint = \"storage/models/base/bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f412d9",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c1006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bf513",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d2bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at storage/models/base/bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "llm = NuclBERT(\n",
    "  checkpoint=checkpoint,\n",
    "  seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37459a60",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918f38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a89be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57687/57687 [00:00<00:00, 2232424.04it/s]\n"
     ]
    }
   ],
   "source": [
    "all_dataset = []\n",
    "for record in tqdm(data):\n",
    "  example = llm.build_input(\n",
    "    sequence=record[\"sequence\"],\n",
    "    target=record[\"target\"],\n",
    "    organism=record.get(\"organism\")\n",
    "\t)\n",
    "  all_dataset.append(example)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "  all_dataset,\n",
    "  test_size=0.05,\n",
    "  random_state=seed,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "391de545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Len: 54802\n",
      "Test Dataset Len: 2885\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Len:\", len(train_dataset))\n",
    "print(\"Test Dataset Len:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9b7cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 18:39:47,416 - INFO - \u001b[32mPreparing dataset...\u001b[0m\n",
      "100%|██████████| 54802/54802 [1:25:23<00:00, 10.70it/s]   \n",
      "2025-10-20 20:22:07,326 - INFO - \u001b[32mDataset prepared!\u001b[0m\n",
      "2025-10-20 20:22:15,955 - INFO - \u001b[32mStarting training...\u001b[0m\n",
      "/home-lib/gustavo.cruz/miniconda3/envs/dna/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44615' max='44615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [44615/44615 1:40:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.604300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.493000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.475500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.447900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 22:03:14,895 - INFO - \u001b[32mTraining complete. You may save the model for later usage.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm.train(\n",
    "  dataset=train_dataset,\n",
    "  params=TrainParams(\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    gradient_accumulation=1,\n",
    "    lr=5e-6,\n",
    "    logging_steps=5000\n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6f4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 22:03:15,085 - INFO - \u001b[32mAttempting to save model at './storage/models/tuned/NuclBERT'\u001b[0m\n",
      "2025-10-20 22:03:19,788 - INFO - \u001b[32mSuccessfully saved at './storage/models/tuned/NuclBERT'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm.save_pretrained(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a20074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2885/2885 [1:46:40<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "refs = []\n",
    "preds = []\n",
    "\n",
    "for data in tqdm(test_dataset):\n",
    "  answer = llm.generate(data)\n",
    "  preds.append(answer)\n",
    "  refs.append(data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace9c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7968290340967777\n",
      "Class: 'I'\n",
      "  - Precision: 0.5885\n",
      "  - Recall:   0.7231\n",
      "  - F1-Score: 0.6489\n",
      "\n",
      "Class: 'E'\n",
      "  - Precision: 0.8059\n",
      "  - Recall:   0.9055\n",
      "  - F1-Score: 0.8528\n",
      "\n",
      "Class: 'U'\n",
      "  - Precision: 0.8394\n",
      "  - Recall:   0.6629\n",
      "  - F1-Score: 0.7408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_refs = []\n",
    "all_preds = []\n",
    "for ref, pred in zip(refs, preds):\n",
    "  min_len = min(len(ref), len(pred))\n",
    "  all_refs.extend(list(ref[:min_len]))\n",
    "  all_preds.extend(list(pred[:min_len]))\n",
    "\n",
    "acc = accuracy_score(all_refs, all_preds)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "labels = [\"I\", \"E\", \"U\"]\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "\tall_refs, all_preds, labels=labels, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Class: '{label}'\")\n",
    "    print(f\"  - Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  - Recall:   {recall[i]:.4f}\")\n",
    "    print(f\"  - F1-Score: {f1[i]:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
