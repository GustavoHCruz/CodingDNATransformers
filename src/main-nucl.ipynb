{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c37f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1e763",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd91030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llms.nucl_classifier.bert import NuclBERT\n",
    "from schemas.train_params import TrainParams\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a404f87",
   "metadata": {},
   "source": [
    "## Params and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d58f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "\n",
    "csv_path = \"nucl-500.csv\"\n",
    "pretrained_model_name = \"NuclBERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b78c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = f\"./storage/data/processed/{csv_path}\"\n",
    "output_path = f\"./storage/models/tuned/{pretrained_model_name}\"\n",
    "checkpoint = \"storage/models/base/bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f412d9",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c1006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bf513",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d2bdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at storage/models/base/bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "llm = NuclBERT(\n",
    "  checkpoint=checkpoint,\n",
    "  seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37459a60",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918f38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a89be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57687/57687 [00:00<00:00, 2312388.92it/s]\n"
     ]
    }
   ],
   "source": [
    "all_dataset = []\n",
    "for record in tqdm(data):\n",
    "  example = llm.build_input(\n",
    "    sequence=record[\"sequence\"],\n",
    "    target=record[\"target\"],\n",
    "    organism=record.get(\"organism\")\n",
    "\t)\n",
    "  all_dataset.append(example)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "  all_dataset,\n",
    "  test_size=0.05,\n",
    "  random_state=seed,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "391de545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Len: 54802\n",
      "Test Dataset Len: 2885\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset Len:\", len(train_dataset))\n",
    "print(\"Test Dataset Len:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9b7cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 10:43:50,769 - INFO - \u001b[32mPreparing dataset...\u001b[0m\n",
      "100%|██████████| 54802/54802 [1:26:19<00:00, 10.58it/s]   \n",
      "2025-10-21 12:26:42,079 - INFO - \u001b[32mDataset prepared!\u001b[0m\n",
      "2025-10-21 12:26:51,547 - INFO - \u001b[32mStarting training...\u001b[0m\n",
      "/home-lib/gustavo.cruz/miniconda3/envs/dna/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='133845' max='133845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [133845/133845 5:05:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.425500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.416400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.402600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.388300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.369800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>0.369500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>0.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.367600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:32:04,975 - INFO - \u001b[32mTraining complete. You may save the model for later usage.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm.train(\n",
    "  dataset=train_dataset,\n",
    "  params=TrainParams(\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    gradient_accumulation=1,\n",
    "    lr=5e-6,\n",
    "    logging_steps=5000\n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6f4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:32:05,162 - INFO - \u001b[32mAttempting to save model at './storage/models/tuned/NuclBERT'\u001b[0m\n",
      "2025-10-21 17:32:09,426 - INFO - \u001b[32mSuccessfully saved at './storage/models/tuned/NuclBERT'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "llm.save_pretrained(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a20074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2885/2885 [1:45:58<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "refs = []\n",
    "preds = []\n",
    "\n",
    "for data in tqdm(test_dataset):\n",
    "  answer = llm.generate(data)\n",
    "  preds.append(answer)\n",
    "  refs.append(data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace9c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8183934384838736\n",
      "Class: 'I'\n",
      "  - Precision: 0.6455\n",
      "  - Recall:   0.7164\n",
      "  - F1-Score: 0.6791\n",
      "\n",
      "Class: 'E'\n",
      "  - Precision: 0.8236\n",
      "  - Recall:   0.9214\n",
      "  - F1-Score: 0.8698\n",
      "\n",
      "Class: 'U'\n",
      "  - Precision: 0.8522\n",
      "  - Recall:   0.6974\n",
      "  - F1-Score: 0.7671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_refs = []\n",
    "all_preds = []\n",
    "for ref, pred in zip(refs, preds):\n",
    "  min_len = min(len(ref), len(pred))\n",
    "  all_refs.extend(list(ref[:min_len]))\n",
    "  all_preds.extend(list(pred[:min_len]))\n",
    "\n",
    "acc = accuracy_score(all_refs, all_preds)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "labels = [\"I\", \"E\", \"U\"]\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "\tall_refs, all_preds, labels=labels, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Class: '{label}'\")\n",
    "    print(f\"  - Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  - Recall:   {recall[i]:.4f}\")\n",
    "    print(f\"  - F1-Score: {f1[i]:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
