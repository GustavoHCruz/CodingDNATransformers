{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d1e763",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd91030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from llms.nucl_classifier.bert import NuclBERT\n",
    "from schemas.train_params import TrainParams\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a404f87",
   "metadata": {},
   "source": [
    "## Params and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d58f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "csv_path = \"nucl-500.csv\"\n",
    "pretrained_model_name = \"NuclBERTModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b78c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = f\"./storage/data/processed/{csv_path}\"\n",
    "output_path = f\"./storage/models/tuned/{pretrained_model_name}\"\n",
    "checkpoint = \"storage/models/base/bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f412d9",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bf513",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = NuclBERT(\n",
    "  checkpoint=checkpoint,\n",
    "  seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37459a60",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = []\n",
    "for record in tqdm(data):\n",
    "  example = llm.build_input(\n",
    "    sequence=record[\"sequence\"],\n",
    "    target=record[\"target\"],\n",
    "    organism=record.get(\"organism\")\n",
    "\t)\n",
    "  all_dataset.append(example)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "  all_dataset,\n",
    "  test_size=0.05,\n",
    "  random_state=seed,\n",
    "  shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6964c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.train(\n",
    "  dataset=train_dataset,\n",
    "  params=TrainParams(\n",
    "    epochs=1,\n",
    "    batch_size=1,\n",
    "    gradient_accumulation=1,\n",
    "    lr=2e-5\n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.save_pretrained(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = []\n",
    "preds = []\n",
    "\n",
    "for data in tqdm(test_dataset):\n",
    "  answer = llm.generate(data)\n",
    "  preds.append(answer)\n",
    "  refs.append(data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_refs = []\n",
    "all_preds = []\n",
    "for ref, pred in zip(refs, preds):\n",
    "  min_len = min(len(ref), len(pred))\n",
    "  all_refs.extend(list(ref[:min_len]))\n",
    "  all_preds.extend(list(pred[:min_len]))\n",
    "\n",
    "acc = accuracy_score(all_refs, all_preds)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "labels = [\"I\", \"E\", \"U\"]\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "\tall_refs, all_preds, labels=labels, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Class: '{label}'\")\n",
    "    print(f\"  - Precision: {precision[i]:.4f}\")\n",
    "    print(f\"  - Recall:   {recall[i]:.4f}\")\n",
    "    print(f\"  - F1-Score: {f1[i]:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
