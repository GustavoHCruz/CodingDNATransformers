{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from typing import Any\n",
    "\n",
    "import editdistance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import Dataset, load_dataset\n",
    "from llms.dna_translator.gpt import DNATranslatorGPT\n",
    "from pandas import DataFrame\n",
    "from schemas.train_params import TrainParams\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34c33e",
   "metadata": {},
   "source": [
    "# Configurations & Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed For Reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Output Folder For Metrics And Checkpoints\n",
    "CHECKPOINT_NAME = \"GeneFormer\"\n",
    "\n",
    "# Training Configuration\n",
    "MAX_EPOCHS = 30\n",
    "PATIENCE = 3\n",
    "MIN_DELTA = 1e-4\n",
    "\n",
    "# Model Context Limit \n",
    "DATA_MAX_LENGTH = 1000\n",
    "\n",
    "# Trivial Thresholds\n",
    "TRIVIAL_THRESHOLD = 0.8\n",
    "AMBIGUOUS_THRESHOLD = 0.65\n",
    "\n",
    "# Similarity Thresholds\n",
    "MAX_PAIRS_PER_SPECIES = 500\n",
    "MAX_INTERSPECIES_PAIRS = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598cfaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024b3d8",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"GustavoHCruz/DNA_Coding_Regions\", split=\"train\")\n",
    "\n",
    "assert isinstance(dataset, Dataset)\n",
    "\n",
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f869ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_proteins(protein_list) -> str:\n",
    "\tseqs = []\n",
    "\tfor p in protein_list:\n",
    "\t\tseq = p.get(\"sequence\", \"\")\n",
    "\t\tif isinstance(seq, str):\n",
    "\t\t\tseqs.append(seq)\n",
    "\treturn \"\".join(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf49104",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(dataset, DataFrame)\n",
    "\n",
    "dataset[\"target\"] = dataset[\"proteins\"].apply(join_proteins).astype(str)\n",
    "mask = (dataset[\"sequence\"].str.len() + dataset[\"target\"].str.len()) < DATA_MAX_LENGTH\n",
    "original_df = dataset[mask]\n",
    "original_df = original_df[[\"sequence\", \"target\", \"organism\"]]\n",
    "\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63616199",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Length:\", len(original_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dfeae2",
   "metadata": {},
   "source": [
    "# Removing Invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = original_df[original_df[\"sequence\"].str.len().ge(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Length:\", len(original_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fa043a",
   "metadata": {},
   "source": [
    "# How Many Trivial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea393c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODON_TABLE = {\n",
    "\t'TTT':'F','TTC':'F','TTA':'L','TTG':'L',\n",
    "\t'CTT':'L','CTC':'L','CTA':'L','CTG':'L',\n",
    "\t'ATT':'I','ATC':'I','ATA':'I','ATG':'M',\n",
    "\t'GTT':'V','GTC':'V','GTA':'V','GTG':'V',\n",
    "\t'TCT':'S','TCC':'S','TCA':'S','TCG':'S',\n",
    "\t'CCT':'P','CCC':'P','CCA':'P','CCG':'P',\n",
    "\t'ACT':'T','ACC':'T','ACA':'T','ACG':'T',\n",
    "\t'GCT':'A','GCC':'A','GCA':'A','GCG':'A',\n",
    "\t'TAT':'Y','TAC':'Y','TAA':'*','TAG':'*',\n",
    "\t'CAT':'H','CAC':'H','CAA':'Q','CAG':'Q',\n",
    "\t'AAT':'N','AAC':'N','AAA':'K','AAG':'K',\n",
    "\t'GAT':'D','GAC':'D','GAA':'E','GAG':'E',\n",
    "\t'TGT':'C','TGC':'C','TGA':'*','TGG':'W',\n",
    "\t'CGT':'R','CGC':'R','CGA':'R','CGG':'R',\n",
    "\t'AGT':'S','AGC':'S','AGA':'R','AGG':'R',\n",
    "\t'GGT':'G','GGC':'G','GGA':'G','GGG':'G'\n",
    "}\n",
    "\n",
    "def translate_frame(seq, frame):\n",
    "\tprotein = []\n",
    "\tfor i in range(frame, len(seq) - 2, 3):\n",
    "\t\tcodon = seq[i:i+3]\n",
    "\t\tprotein.append(CODON_TABLE.get(codon, 'X'))\n",
    "\treturn ''.join(protein)\n",
    "\n",
    "def protein_segments(protein):\n",
    "\treturn [seg for seg in protein.split('*') if len(seg) > 0]\n",
    "\n",
    "def similarity(a, b):\n",
    "\tif len(a) == 0 or len(b) == 0:\n",
    "\t\treturn 0.0\n",
    "\tdist = editdistance.eval(a, b)\n",
    "\treturn 1.0 - dist / max(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_similarities = []\n",
    "\n",
    "for _, row in tqdm(original_df.iterrows(), total=len(original_df)):\n",
    "\tdna = row[\"sequence\"].upper()\n",
    "\ttarget = row[\"target\"]\n",
    "\n",
    "\tbest = 0.0\n",
    "\n",
    "\tfor frame in (0, 1, 2):\n",
    "\t\tprotein = translate_frame(dna, frame)\n",
    "\t\tsegments = protein_segments(protein)\n",
    "\n",
    "\t\tfor seg in segments:\n",
    "\t\t\tsim = similarity(seg, target)\n",
    "\t\t\tif sim > best:\n",
    "\t\t\t\tbest = sim\n",
    "\n",
    "\tmax_similarities.append(best)\n",
    "\n",
    "original_df[\"max_frame_similarity\"] = max_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab469e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sim):\n",
    "\tif sim >= TRIVIAL_THRESHOLD:\n",
    "\t\treturn \"trivial\"\n",
    "\telif sim >= AMBIGUOUS_THRESHOLD:\n",
    "\t\treturn \"ambiguous\"\n",
    "\telse:\n",
    "\t\treturn \"genomic\"\n",
    "\n",
    "original_df[\"translation_class\"] = original_df[\"max_frame_similarity\"].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distribution:\")\n",
    "print(original_df[\"translation_class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentils:\")\n",
    "print(original_df[\"translation_class\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df35efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(original_df[\"max_frame_similarity\"], bins=50)\n",
    "plt.axvline(TRIVIAL_THRESHOLD, color=\"yellow\")\n",
    "plt.axvline(AMBIGUOUS_THRESHOLD, color=\"red\")\n",
    "plt.xlabel(\"Max frame similarity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Frame-based translation similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f305f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomic = original_df[original_df[\"translation_class\"] == \"genomic\"]\n",
    "ambiguous = original_df[original_df[\"translation_class\"] == \"ambiguous\"]\n",
    "trivial = original_df[original_df[\"translation_class\"] == \"trivial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceeb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Genomics: {len(genomic)} ({len(genomic)/len(original_df)*100:.2f}%)\")\n",
    "print(f\"Other (trivial + ambiguous): {len(ambiguous) + len(trivial)} ({(len(ambiguous) + len(trivial))/len(original_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45380da",
   "metadata": {},
   "source": [
    "# Data Structure & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc570eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = genomic.copy()\n",
    "\n",
    "stats[\"organism_norm\"] = (\n",
    "\tstats[\"organism\"]\n",
    "\t.astype(str)\n",
    "\t.str.strip()\n",
    "\t.str.lower()\n",
    ")\n",
    "\n",
    "print(f\"Total of Sequences: {len(stats)}\")\n",
    "print(f\"Total of Species: {stats['organism_norm'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f346548",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_stats = (\n",
    "\tstats\n",
    "\t.groupby(\"organism_norm\")\n",
    "\t.agg(\n",
    "\t\tnum_sequences=(\"sequence\", \"count\"),\n",
    "\t\tavg_seq_length=(\"sequence\", lambda x: x.str.len().mean())\n",
    "\t)\n",
    "\t.reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a14873",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of sequences per species:\")\n",
    "print(species_stats[\"num_sequences\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d452f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average sequence size by species:\")\n",
    "print(species_stats[\"avg_seq_length\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2eb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Species with MORE sequences:\")\n",
    "print(species_stats.loc[species_stats[\"num_sequences\"].idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34514cd",
   "metadata": {},
   "source": [
    "# Similarity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39126080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_similarity(a, b):\n",
    "\tif len(a) == 0 or len(b) == 0:\n",
    "\t\treturn 0.0\n",
    "\tdist = editdistance.eval(a, b)\n",
    "\treturn 1.0 - dist / max(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec71d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_results = []\n",
    "\n",
    "for organism, group in tqdm(genomic.groupby(\"organism\"), desc=\"Intra-species\"):\n",
    "\tsequences = group[\"sequence\"].tolist()\n",
    "\n",
    "\tif len(sequences) < 2:\n",
    "\t\tcontinue\n",
    "\n",
    "\tpairs = list(combinations(sequences, 2))\n",
    "\trandom.shuffle(pairs)\n",
    "\tpairs = pairs[:MAX_PAIRS_PER_SPECIES]\n",
    "\n",
    "\tfor a, b in pairs:\n",
    "\t\tsim = dna_similarity(a, b)\n",
    "\t\tintra_results.append({\n",
    "\t\t\t\"organism\": organism,\n",
    "\t\t\t\"similarity\": sim\n",
    "\t\t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15795724",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_df = pd.DataFrame(intra_results)\n",
    "\n",
    "print(\"INTRA-SPECIES\")\n",
    "print(intra_df[\"similarity\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "organisms = genomic[\"organism\"].unique().tolist()\n",
    "inter_results = []\n",
    "\n",
    "pairs_done = 0\n",
    "\n",
    "for org_a, org_b in tqdm(list(combinations(organisms, 2)), desc=\"Inter-species\"):\n",
    "\tif pairs_done >= MAX_INTERSPECIES_PAIRS:\n",
    "\t\tbreak\n",
    "\n",
    "\tseqs_a = genomic[genomic[\"organism\"] == org_a][\"sequence\"].tolist()\n",
    "\tseqs_b = genomic[genomic[\"organism\"] == org_b][\"sequence\"].tolist()\n",
    "\n",
    "\tif not seqs_a or not seqs_b:\n",
    "\t\tcontinue\n",
    "\n",
    "\ta = random.choice(seqs_a)\n",
    "\tb = random.choice(seqs_b)\n",
    "\n",
    "\tsim = dna_similarity(a, b)\n",
    "\tinter_results.append({\n",
    "\t\t\"organism_a\": org_a,\n",
    "\t\t\"organism_b\": org_b,\n",
    "\t\t\"similarity\": sim\n",
    "\t})\n",
    "\n",
    "\tpairs_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = pd.DataFrame(inter_results)\n",
    "\n",
    "print(\"INTER-SPECIES\")\n",
    "print(inter_df[\"similarity\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a86c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(\n",
    "\tintra_df[\"similarity\"],\n",
    "\tbins=50,\n",
    "\talpha=0.6,\n",
    "\tlabel=\"Intra-species\",\n",
    "\tdensity=True\n",
    ")\n",
    "plt.hist(\n",
    "\tinter_df[\"similarity\"],\n",
    "\tbins=50,\n",
    "\talpha=0.6,\n",
    "\tlabel=\"Inter-species\",\n",
    "\tdensity=True\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Genomic similarity\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.title(\"Intra vs Inter species similarity distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e797258",
   "metadata": {},
   "source": [
    "# Splitting Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ef162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_organism(\n",
    "\tdf,\n",
    "\ttrain_ratio=0.85,\n",
    "\ttest_ratio=0.10,\n",
    "\tval_ratio=0.05\n",
    "):\n",
    "\tassert abs(train_ratio + test_ratio + val_ratio - 1.0) < 1e-6\n",
    "\n",
    "\torganisms = df[\"organism\"].unique().tolist()\n",
    "\trandom.shuffle(organisms)\n",
    "\n",
    "\tn_orgs = len(organisms)\n",
    "\n",
    "\tn_train = int(n_orgs * train_ratio)\n",
    "\tn_test = int(n_orgs * test_ratio)\n",
    "\n",
    "\ttrain_orgs = set(organisms[:n_train])\n",
    "\ttest_orgs = set(organisms[n_train:n_train + n_test])\n",
    "\tval_orgs = set(organisms[n_train + n_test:])\n",
    "\n",
    "\ttrain_df = df[df[\"organism\"].isin(train_orgs)].reset_index(drop=True)\n",
    "\ttest_df = df[df[\"organism\"].isin(test_orgs)].reset_index(drop=True)\n",
    "\tval_df = df[df[\"organism\"].isin(val_orgs)].reset_index(drop=True)\n",
    "\n",
    "\tprint(\"=\" * 60)\n",
    "\tprint(f\"Total organisms: {n_orgs}\")\n",
    "\tprint()\n",
    "\tprint(\"Organism split:\")\n",
    "\tprint(f\"  Train: {len(train_orgs)} organisms\")\n",
    "\tprint(f\"  Test : {len(test_orgs)} organisms\")\n",
    "\tprint(f\"  Val  : {len(val_orgs)} organisms\")\n",
    "\tprint()\n",
    "\tprint(\"Sequence split:\")\n",
    "\tprint(f\"  Train: {len(train_df)} sequences\")\n",
    "\tprint(f\"  Test : {len(test_df)} sequences\")\n",
    "\tprint(f\"  Val  : {len(val_df)} sequences\")\n",
    "\tprint()\n",
    "\tprint(\"Approximate ratios (by sequence):\")\n",
    "\ttotal_seq = len(df)\n",
    "\tprint(f\"  Train: {len(train_df)/total_seq:.3f}\")\n",
    "\tprint(f\"  Test : {len(test_df)/total_seq:.3f}\")\n",
    "\tprint(f\"  Val  : {len(val_df)/total_seq:.3f}\")\n",
    "\tprint(\"=\" * 60)\n",
    "\n",
    "\treturn train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5facc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, val_df = split_by_organism(\n",
    "\tgenomic\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49b28a",
   "metadata": {},
   "source": [
    "# Training To Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = DNATranslatorGPT(\n",
    "  checkpoint=\"./storage/models/base/gpt2\",\n",
    "  seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df.to_dict(orient=\"records\")\n",
    "test_data = test_df.to_dict(orient=\"records\")\n",
    "val_data = val_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14363dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for record in tqdm(train_data, desc=\"Train Data\"):\n",
    "\texample = llm.build_input(\n",
    "\t\tdna_sequence=record[\"sequence\"],\n",
    "\t\torganism=record[\"organism\"],\n",
    "\t\tprotein_sequence=record[\"target\"]\n",
    "\t)\n",
    "\ttrain_dataset.append(example)\n",
    "\n",
    "test_dataset = []\n",
    "for record in tqdm(test_data, desc=\"Test Data\"):\n",
    "\texample = llm.build_input(\n",
    "\t\tdna_sequence=record[\"sequence\"],\n",
    "\t\torganism=record[\"organism\"],\n",
    "\t\tprotein_sequence=record[\"target\"]\n",
    "\t)\n",
    "\ttest_dataset.append(example)\n",
    "\n",
    "eval_dataset = []\n",
    "for record in tqdm(val_data, desc=\"Eval Data\"):\n",
    "\texample = llm.build_input(\n",
    "\t\tdna_sequence=record[\"sequence\"],\n",
    "\t\torganism=record[\"organism\"],\n",
    "\t\tprotein_sequence=record[\"target\"]\n",
    "\t)\n",
    "\teval_dataset.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lengths = [len(example[\"dna_sequence\"]) for example in train_dataset]\n",
    "eval_lengths = [len(example[\"dna_sequence\"]) for example in eval_dataset]\n",
    "test_lengths = [len(example[\"dna_sequence\"]) for example in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a29912",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_lengths, kde=True, bins=40, color=\"skyblue\", label=\"Train\")\n",
    "sns.histplot(eval_lengths, kde=True, bins=40, color=\"green\", label=\"Eval\")\n",
    "sns.histplot(test_lengths, kde=True, bins=40, color=\"salmon\", label=\"Test\")\n",
    "\n",
    "plt.title(\"Sequence Length Distribution\", fontsize=16, weight=\"bold\")\n",
    "plt.xlabel(\"Sequence Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b25d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_similarity(\n",
    "\tpred: str,\n",
    "\ttarget: str\n",
    ") -> tuple[float, float]:\n",
    "\tden = max(len(pred), len(target))\n",
    "\tif den <= 0:\n",
    "\t\treturn 1.0, 1.0\n",
    "\tdist = editdistance.eval(pred, target)\n",
    "\tsim = 1.0 - (dist / den)\n",
    "\n",
    "\tif sim < 0.0:\n",
    "\t\treturn 0.0, 0.0\n",
    "\tif sim > 1.0:\n",
    "\t\treturn 1.0, 1.0\n",
    "\treturn dist, sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(\n",
    "\tllm: DNATranslatorGPT,\n",
    "\ttest_dataset: list,\n",
    "\tshow_tqdm: bool = True\n",
    ") -> tuple[list[dict[str, Any]], dict[str, Any]]:\n",
    "\tresults = []\n",
    "\tsims = []\n",
    "\tit = tqdm(test_dataset, desc=\"Eval (test)\", leave=False) if show_tqdm else test_dataset\n",
    "\n",
    "\tfor data in it:\n",
    "\t\tpred = llm.generate(data)\n",
    "\t\ttarget = data[\"protein_sequence\"]\n",
    "\t\torganism = data[\"organism\"]\n",
    "\n",
    "\t\texact_match = int(pred == target)\n",
    "\n",
    "\t\tdist, sim = safe_similarity(pred, target)\n",
    "\t\tresults.append({\n",
    "\t\t\t\"target\": target,\n",
    "\t\t\t\"prediction\": pred,\n",
    "\t\t\t\"edit_distance\": dist,\n",
    "\t\t\t\"similarity\": sim,\n",
    "\t\t\t\"organism\": organism,\n",
    "\t\t\t\"exact_match\": exact_match\n",
    "\t\t})\n",
    "\t\tsims.append(sim)\n",
    "\n",
    "\tmean = float(np.mean(sims)) if results else 0.0\n",
    "\tstd = float(np.std(sims)) if results else 0.0\n",
    "\n",
    "\treturn results, {\n",
    "\t\t\"mean\": mean,\n",
    "\t\t\"std\": std,\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee879a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_json(\n",
    "\tpath: str,\n",
    "\tpayload: dict[str, Any]\n",
    ") -> None:\n",
    "\tos.makedirs(path, exist_ok=True)\n",
    "\twith open(os.path.join(path, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "\t\tjson.dump(payload, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f150823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Datasets\n",
    "\n",
    "train_dataset = llm.prepare_dataset(train_dataset)\n",
    "eval_dataset = llm.prepare_dataset(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1410aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean = -math.inf\n",
    "best_epoch = -1\n",
    "epochs_no_improve = 0\n",
    "\n",
    "history: list[dict[str, Any]] = []\n",
    "\n",
    "save_last_dir = f\"output/{CHECKPOINT_NAME}_last\"\n",
    "save_best_dir = f\"output/{CHECKPOINT_NAME}_best\"\n",
    "\n",
    "pbar = tqdm(total=MAX_EPOCHS, desc=\"Global epochs\", dynamic_ncols=True)\n",
    "\n",
    "best_results = []\n",
    "for epoch_idx in range(MAX_EPOCHS):\n",
    "\tglobal_epoch = epoch_idx + 1\n",
    "\n",
    "\tprint(f\"\\n[Train] Global epoch {global_epoch}/{MAX_EPOCHS} starting...\")\n",
    "\n",
    "\tllm.train(\n",
    "\t\ttrain_dataset=train_dataset,\n",
    "\t\tparams=TrainParams(\n",
    "\t\t\tepochs=1,\n",
    "\t\t\tbatch_size=4,\n",
    "\t\t\tgradient_accumulation=4,\n",
    "\t\t\tlr=3e-5\n",
    "\t\t),\n",
    "\t\teval_dataset=eval_dataset\n",
    "\t)\n",
    "\n",
    "\tprint(f\"[Eval] Global epoch {global_epoch}: evaluating on test set...\")\n",
    "\tresults, metrics = evaluate_on_test(llm, test_dataset, show_tqdm=True)\n",
    "\n",
    "\tmean_similarity = metrics[\"mean\"]\n",
    "\tstd_similarity = metrics[\"std\"]\n",
    "\tprint(f\"[Eval] Global epoch {global_epoch}: mean similarity = {mean_similarity:.4f} Â± {std_similarity:.4f}\")\n",
    "\n",
    "\tprint(f\"[Save] Saving LAST -> {save_last_dir}\")\n",
    "\tllm.save_pretrained(save_last_dir)\n",
    "\tpd.DataFrame(results).to_csv(f\"output/results_last.csv\")\n",
    "\n",
    "\trow = {\n",
    "\t\t\"global_epoch\": global_epoch,\n",
    "\t\t\"mean_similarity\": mean_similarity,\n",
    "\t\t\"std_similarity\": std_similarity,\n",
    "\t\t\"best_mean_so_far\": best_mean,\n",
    "\t\t\"epochs_no_improve\": epochs_no_improve,\n",
    "\t}\n",
    "\thistory.append(row)\n",
    "\tsave_metrics_json(save_last_dir, {\n",
    "\t\t\"last_epoch\": global_epoch,\n",
    "\t\t\"metrics\": metrics,\n",
    "\t\t\"history_tail\": history[-10:],\n",
    "\t})\n",
    "\n",
    "\tif mean_similarity > best_mean + MIN_DELTA:\n",
    "\t\tbest_mean = mean_similarity\n",
    "\t\tbest_epoch = global_epoch\n",
    "\t\tepochs_no_improve = 0\n",
    "\n",
    "\t\tprint(f\"[Best] New BEST at epoch {global_epoch}: {best_mean:.4f}. Saving BEST -> {save_best_dir}\")\n",
    "\t\tllm.save_pretrained(save_best_dir)\n",
    "\t\tpd.DataFrame(results).to_csv(\"output/results_best.csv\")\n",
    "\t\tbest_results = results\n",
    "\n",
    "\t\tsave_metrics_json(save_best_dir, {\n",
    "\t\t\t\"best_epoch\": best_epoch,\n",
    "\t\t\t\"best_mean\": best_mean,\n",
    "\t\t\t\"metrics\": metrics,\n",
    "\t\t})\n",
    "\n",
    "\telse:\n",
    "\t\tepochs_no_improve += 1\n",
    "\t\tprint(f\"[Best] No improvement (best={best_mean:.4f} @ epoch {best_epoch}). Patience: {epochs_no_improve}/{PATIENCE}\")\n",
    "\t\n",
    "\tpbar.set_postfix({\n",
    "\t\t\"mean\": f\"{mean_similarity:.4f}\",\n",
    "\t\t\"best\": f\"{best_mean:.4f}\",\n",
    "\t\t\"no_impr\": f\"{epochs_no_improve}/{PATIENCE}\",\n",
    "\t})\n",
    "\tpbar.update(1)\n",
    "\n",
    "\tif epochs_no_improve >= PATIENCE:\n",
    "\t\tprint(f\"[Stop] Early stopping triggered: {PATIENCE} epochs without improvement.\")\n",
    "\t\tbreak\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "print(\"\\n[Done]\")\n",
    "print(f\"- BEST: epoch {best_epoch}, mean similarity {best_mean:.4f} -> {save_best_dir}\")\n",
    "print(f\"- LAST: epoch {history[-1]['global_epoch'] if history else 0} -> {save_last_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31d0ce",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_similarities(\n",
    "\tsimilarities: list[float],\n",
    "\texact_matches: list[int]\n",
    ") -> dict[str, float]:\n",
    "\tsims = np.array(similarities, dtype=float)\n",
    "\texacts = np.array(exact_matches, dtype=float)\n",
    "\n",
    "\treturn {\n",
    "\t\t\"n\": int(len(sims)),\n",
    "\t\t\"mean\": float(np.mean(sims)) if len(sims) else 0.0,\n",
    "\t\t\"std\": float(np.std(sims)) if len(sims) else 0.0,\n",
    "\t\t\"median\": float(np.median(sims)) if len(sims) else 0.0,\n",
    "\t\t\"p75\": float(np.percentile(sims, 75)) if len(sims) else 0.0,\n",
    "\t\t\"p90\": float(np.percentile(sims, 90)) if len(sims) else 0.0,\n",
    "\t\t\"exact_match_rate\": float(np.mean(exacts)) if len(exacts) else 0.0,\n",
    "\t}\n",
    "\n",
    "all_metrics = compute_metrics_from_similarities(\n",
    "\t[r[\"similarity\"] for r in best_results],\n",
    "\t[r[\"exact_match\"] for r in best_results]\n",
    ")\n",
    "\n",
    "best_by_target: dict[str, dict] = {}\n",
    "\n",
    "for r in best_results:\n",
    "\tt = r[\"target\"]\n",
    "\tif t not in best_by_target or r[\"similarity\"] > best_by_target[t][\"similarity\"]:\n",
    "\t\tbest_by_target[t] = r\n",
    "\n",
    "unique_target_results = list(best_by_target.values())\n",
    "\n",
    "unique_target_metrics = compute_metrics_from_similarities(\n",
    "\t[r[\"similarity\"] for r in unique_target_results],\n",
    "\t[r[\"exact_match\"] for r in unique_target_results]\n",
    ")\n",
    "\n",
    "print(f\"Eval Dataset Length:\", len(eval_dataset))\n",
    "\n",
    "print(\"All (sequence-weighted):\", all_metrics)\n",
    "print(\"Unique target:\", unique_target_metrics)\n",
    "\n",
    "target_counts = defaultdict(int)\n",
    "for r in best_results:\n",
    "\ttarget_counts[r[\"target\"]] += 1\n",
    "\n",
    "counts = np.array(list(target_counts.values()), dtype=int)\n",
    "print(\"\\nTarget repetition diagnostics:\")\n",
    "print(\"unique targets:\", len(target_counts))\n",
    "print(\"total sequences:\", len(best_results))\n",
    "print(\"median occurrences per target:\", int(np.median(counts)))\n",
    "print(\"p90 occurrences per target:\", int(np.percentile(counts, 90)))\n",
    "print(\"max occurrences for a target:\", int(np.max(counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_counts = defaultdict(int)\n",
    "for r in best_results:\n",
    "\torg_counts[r[\"organism\"]] += 1\n",
    "\n",
    "vals = np.array(list(org_counts.values()), dtype=int)\n",
    "\n",
    "print(\"Organisms in test:\", len(vals))\n",
    "print(\"Seqs per organism - median:\", int(np.median(vals)))\n",
    "print(\"Seqs per organism - p75:\", int(np.percentile(vals, 75)))\n",
    "print(\"Seqs per organism - p90:\", int(np.percentile(vals, 90)))\n",
    "print(\"Seqs per organism - max:\", int(np.max(vals)))\n",
    "\n",
    "bins = {\n",
    "\t\"1\": int(np.sum(vals == 1)),\n",
    "\t\"2-5\": int(np.sum((vals >= 2) & (vals <= 5))),\n",
    "\t\"6-20\": int(np.sum((vals >= 6) & (vals <= 20))),\n",
    "\t\">20\": int(np.sum(vals > 20)),\n",
    "}\n",
    "\n",
    "print(\"\\nBins (#seqs per organism):\")\n",
    "for k, v in bins.items():\n",
    "\tprint(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
